{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando a Conexão com o Azure DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupado chaves relevantes\n",
    "ClientId = ''\n",
    "ClientSecret = ''\n",
    "TenantID = ''\n",
    "\n",
    "#Combinando DirectoryID em uma string\n",
    "Endpoint = 'https://login.microsoftonline.com/{}/oauth2/token'.format(TenantID)\n",
    "\n",
    "#Criando configurações para conexão\n",
    "spark.conf.set('fs.azure.account.auth.type','Oauth')\n",
    "spark.conf.set('fs.azure.account.oauth.provider.type', 'org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider')\n",
    "spark.conf.set('fs.azure.account.oauth.client.id', ClientId)\n",
    "spark.conf.set('fs.azure.account.oauth.client.secret', ClientSecret)\n",
    "spark.conf.set('fs.azure.account.oauth.client.endpoint', Endpoint)\n",
    "\n",
    "# https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados = [('Lucas',26,'SãoPaulo','1994-09-01','M',4000),\n",
    "  ('Luana',20,'SãoPaulo','2000-09-05','F',1200),\n",
    "  ('Katia',35,'SãoPaulo','1985-03-16','F',1600)\n",
    "]\n",
    "Colunas = [\"Nome\",\"Idade\",\"Estado\",\"DataNascimento\",\"Sexo\",\"Salario\"]\n",
    "df = spark.createDataFrame(data=Dados, schema = Colunas)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o DataFrame dentro do Azure DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.format(\"csv\").option(\"header\", \"true\").save(\"adl://teste.azuredatalakestore.net/DF/Teste.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copiando, Movendo, Renomeando e Excluindo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copiando o caminho do ultimo arquivo na pasta 'Teste'\n",
    "file=dbutils.fs.ls('adl://teste.azuredatalakestore.net/DF/Teste.csv')[-1].path \n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movendo o arquivo para pasta 'DF'\n",
    "dbutils.fs.mv(file, 'adl://teste.azuredatalakestore.net/DF/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copiando o caminho do ultimo arquivo na pasta 'DF'\n",
    "file=dbutils.fs.ls('adl://teste.azuredatalakestore.net/DF')[-1].path \n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomeando o Arquivo para 'NovoNome.csv'\n",
    "dbutils.fs.mv(file, 'adl://teste.azuredatalakestore.net/DF/NovoNome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluindo a pasta Teste\n",
    "dbutils.fs.rm('adl://teste.azuredatalakestore.net/DF/Teste.csv/', recurse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
